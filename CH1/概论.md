# 概论

**1.先验概率和后验概率**

先验概率：根据经验由以前的数据推断还没发生的事件的发生概率。（啥也没有，直接猜）

后验概率：事件已经发生，根据发生的事件推断导致该事件发生的某一(些)原因的概率。（已知XX，去猜YY）

贝叶斯估计（Bayesian estimation）：
$$
P(H|E)=\frac{P(H)P(E|H)}{P(E)}
$$
* $H$：假说，一般来说有很多种假说；
* $E$：证据，即还未用来计算先验概率的数据；
* $P(H)$：先验概率，即观察到数据 $E$ 之前，假说 $H$ 的概率；
* $P(H|E)$：后验概率，即观察到数据 $E$ 之后，假说 $H$ 的概率；
* $P(E|H)$：假设 $H$ 成立时，观察到 $E$ 的几率。在 $H$ 不变时，是 $E$ 的似然函数。

**2.概率密度函数和似然函数和最大似然函数**

概率密度函数：$f(x)$

条件概率密度函数：$f(x|\theta)$ ，其中 $\theta$ 已知。

似然函数：$f(\theta|x)=L(\theta)=L(x_1,x_2,\cdots,x_n;\theta)=\prod_{i=1}^{n}{p(x_i;\theta)}$ 其中 $x_i$ 为已知的样本值，$P\{X=x\}=p(x;\theta)$。

最大似然函数：当 $\theta=\theta_i$ 时，似然函数取得最大值，即取得参数 $\theta_i$ 的后验概率最大。

![image-20200710094727084](%E6%A6%82%E8%AE%BA.assets/image-20200710094727084.png)

目前看不太懂

## 统计学习方法三要素

- 模型
- 策略（损失函数）
- 算法（优化方法）

### 模型

模型指所要学习的条件概率分布或决策函数。模型的假设空间 $\cal{F}$（hypothesis space）包含所有可能的条件概率分布或决策函数。
$$
{\cal{F}}=\{f|Y=f_{\theta}(X),\theta \in {\mathrm{R^n}}\}
$$

$$
{\cal{F}}=\{P|P_{\theta}(Y|X),\theta \in {\mathrm{R^n}}\}
$$

* $X$ 是定义在输入空间 $\cal{X}$ 上的变量；
* $Y$ 是定义在输出空间 $\cal{Y}$ 上的变量；
* $\cal{F}$ 是由参数 $\theta$ 决定的 *决策函数族* 或 *条件概率分布族*。

### 策略

**损失函数与风险函数**

* 损失函数 $L(Y,f(x))$

  $Y$ 为真实值，$f(x)$ 为预测值，损失函数即是一个度量预测错误程度的非负实值函数。

  1. 0 - 1 损失函数（0 - 1 loss function）
     $$
     L(Y,f(x))=\begin{cases}
     1, & Y\neq f(X)\\
     0, & Y= f(X)
     \end{cases}
     $$

  2. 平方损失函数（quadratic loss function）
     $$
     L(Y,f(x))=(Y-f(x))^2
     $$

  3. 绝对损失函数（absolute loss function）
     $$
     L(Y,f(x))=|Y-f(x)|
     $$

  4. 对数损失函数（logarithmic loss function）或对数似然损失函数（log-likehood loss function）
     $$
     L(Y,P(Y|X))=-logP(Y|X)
     $$

* 风险函数（risk function）或期望损失（expected loss） $R_{\exp}(f)$
  $$
  \begin{aligned}
  R_{\exp}(f)&=E_p[{L(Y,f(X))}]\\
  &=\int_{\cal{X\times Y}}{L(y,f(x))P(x,y)dxdy}
  \end{aligned}
  $$
  风险函数即损失函数的期望，但由于联合分布 $P(x,y)$ 为未知（若已知 $P(x,y)$ ，则有 $P(Y)=\frac{P(X,Y)}{P(X)}$，$P(Y)$ 为需要预测的真实标签的分布）。

* 经验风险 $R_{\mathrm{emp}}(f)$

  $$
  R_{\mathrm{emp}}(f)=\frac{1}{N}\sum_{i=1}^{N}{L(y_i,f(x_i))}
  $$
  根据大数定理，当样本容量 $N$ 趋近于无穷时，经验风险 $R_{\mathrm{emp}}(f)$ 趋近于期望风险 $R_{\exp}(f)$，故可用经验风险来估计期望风险。

**监督学习基本策略**

* 经验风险最小化（empirical risk minimization，ERM）

  经验风险最小的模型是最优的模型，即求解最优化问题：
  $$
  \min_{f\in \cal{F}}\frac{1}{N}\sum_{i=1}^{N}{L(y_i,f(x_i))}
  $$
  
* 结构风险最小化（SRM）

  为了防止 ERM 在样本容量很小时可能出现的过拟合（over-fitting）现象，等价于正则化（regularizer）。结构风险在经验风险的基础上加上了表示模型复杂度的正则化项（regularizer）或罚项（penalty term），定义为：
$$
R_{\mathrm{srm}}(f)=\frac{1}{N}L(y_i,f(x_i))+\lambda J(f)
$$
  即求解最优化问题：
$$
  \min_{f\in \cal{F}}\frac{1}{N}L(y_i,f(x_i))+\lambda J(f)
$$

  * $J(f)$ 为模型复杂度的单调递增函数；
  * $\lambda \geq 0$ 为权衡经验风险和模型复杂度的系数。

### 算法

指学习模型的具体计算方法，如最优化问题。